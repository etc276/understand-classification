{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import graphviz \n",
    "from graphviz import render\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Design a set of rules to classify data\n",
    "\n",
    "* problem: decide which color I like\n",
    "* data size: 200\n",
    "* feature:\n",
    "    * `R` - red\n",
    "    * `G` - green\n",
    "    * `B` - blue\n",
    "    * range from 0 to 255\n",
    "    \n",
    "    \n",
    "* absolutely right rule\n",
    "    * 60 < R < 155 and G < 100 and B > 160, then yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data = np.zeros([200, 4]) \n",
    "# feature_name = ['R', 'G', 'B', 'Label']\n",
    "\n",
    "# for i in range(100):\n",
    "#     Data[i][0] = int(random.uniform(60,155))\n",
    "#     Data[i][1] = int(random.uniform(0,100))\n",
    "#     Data[i][2] = int(random.uniform(160,255))\n",
    "#     Data[i][3] = 1\n",
    "        \n",
    "#     Data[100 + i][0] = int(random.uniform(0,120))\n",
    "#     Data[100 + i][1] = int(random.uniform(0,255))\n",
    "#     Data[100 + i][2] = int(random.uniform(0,170))\n",
    "#     Data[100 + i][3] = 0\n",
    "    \n",
    "# with open('data.csv', 'w', newline='') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     writer.writerow(feature_name)\n",
    "#     for i in range(200):\n",
    "#          writer.writerow(Data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "with open('data.csv', 'r', newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        X.append(row[:-1])\n",
    "        y.append(row[-1])   \n",
    "\n",
    "y = np.array(y[1:])\n",
    "X = np.array(X[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Use the data generated in Step 1 to construct the classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier is used\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print('Accuracy = ', accuracy_score(y_pred, y_test))\n",
    "print(feature_name[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulization\n",
    "src = Source('digraph \"the holy hand grenade\" { rankdir=LR; 1 -> 2 -> 3 -> lob }')\n",
    "dot_data = tree.export_graphviz(classifier, out_file=None,feature_names=feature_name[:-1], class_names=['yes', 'no'],filled=True, rounded=True)   \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"show_rule\") \n",
    "graphviz.Source(dot_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compare the rules in the decision tree from Step 2 and the rules used to generate the  \"absolutely right\" data \n",
    "\n",
    "### Absolutely right rule\n",
    "\n",
    "* rule 0: 60 < R < 155 and G < 100 and B > 160 ===> yes\n",
    "\n",
    "### Result from decision tree\n",
    "* rule 1: R <= 54 and G <= 118.5 and B <= 164.5 ===> no\n",
    "* rule 2: B <= 160.5 ===> no \n",
    "\n",
    "\n",
    "### Compare\n",
    "\n",
    "* rule 1: similar to absolutely right rule\n",
    "* rule 2: far from absolutely right rule\n",
    "* result: only 97% accuracy\n",
    "* guess: feature overlapping in label 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Discuss anything you can \n",
    "\n",
    "> try other classifiers\n",
    "\n",
    "* Random Forest: higher accuracy than decision tree\n",
    "* Extra Tree: lower accuracy than decicsion tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "classifier_rf = RandomForestClassifier(n_estimators=100, max_depth=3,random_state=0)\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "y_pred = classifier_rf.predict(X_test)\n",
    "print('Accuracy = ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Tree\n",
    "clf = tree.ExtraTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Accuracy = ', accuracy_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
